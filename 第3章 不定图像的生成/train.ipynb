{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26134228",
   "metadata": {},
   "outputs": [],
   "source": [
    "#第3章/全局常量\n",
    "repo_id = 'lansinuote/diffusion.1.unconditional'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8560ef3b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration huggan--flowers-102-categories-2ab3d0588f2a8da7\n",
      "Found cached dataset parquet (/root/.cache/huggingface/datasets/huggan___parquet/huggan--flowers-102-categories-2ab3d0588f2a8da7/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['image'],\n",
       "    num_rows: 8189\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#第3章/加载数据集\n",
    "from datasets import load_dataset\n",
    "\n",
    "load_dataset('huggan/flowers-102-categories', split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e60aec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration lansinuote--diffusion.1.unconditional-a9e8dd8d646db18f\n",
      "Found cached dataset parquet (/root/.cache/huggingface/datasets/lansinuote___parquet/lansinuote--diffusion.1.unconditional-a9e8dd8d646db18f/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Dataset({\n",
       "     features: ['image'],\n",
       "     num_rows: 8189\n",
       " }),\n",
       " {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=752x500>})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#第3章/使用笔者转载的数据集\n",
    "dataset = load_dataset(path=repo_id, split='train')\n",
    "\n",
    "dataset, dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "102e0a89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dataset({\n",
       "     features: ['image'],\n",
       "     num_rows: 8189\n",
       " }),\n",
       " torch.Size([3, 64, 64]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#第3章/数据集预处理\n",
    "import torchvision\n",
    "\n",
    "#图像增强和编码\n",
    "compose = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize(\n",
    "        64, interpolation=torchvision.transforms.InterpolationMode.BILINEAR),\n",
    "    torchvision.transforms.RandomCrop(64),\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "\n",
    "def f(data):\n",
    "    image = [compose(i) for i in data['image']]\n",
    "    return {'image': image}\n",
    "\n",
    "\n",
    "#因为图像增强在每个epoch中要动态计算,所以不能简单地用map处理\n",
    "dataset.set_transform(f)\n",
    "\n",
    "dataset, dataset[0]['image'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ef5b1fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, torch.Size([16, 3, 64, 64]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#第3章/定义loader\n",
    "import torch\n",
    "\n",
    "loader = torch.utils.data.DataLoader(dataset,\n",
    "                                     batch_size=16,\n",
    "                                     shuffle=True,\n",
    "                                     drop_last=False)\n",
    "\n",
    "len(loader), next(iter(loader))['image'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9026717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11367.3219"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#第3章/定义模型\n",
    "from diffusers import UNet2DModel\n",
    "\n",
    "#定义模型,随机初始化参数\n",
    "model = UNet2DModel(\n",
    "    sample_size=64,\n",
    "    in_channels=3,\n",
    "    out_channels=3,\n",
    "    layers_per_block=2,\n",
    "    block_out_channels=(128, 128, 256, 256, 512, 512),\n",
    "    down_block_types=(\n",
    "        'DownBlock2D',\n",
    "        'DownBlock2D',\n",
    "        'DownBlock2D',\n",
    "        'DownBlock2D',\n",
    "        'AttnDownBlock2D',\n",
    "        'DownBlock2D',\n",
    "    ),\n",
    "    up_block_types=(\n",
    "        'UpBlock2D',\n",
    "        'AttnUpBlock2D',\n",
    "        'UpBlock2D',\n",
    "        'UpBlock2D',\n",
    "        'UpBlock2D',\n",
    "        'UpBlock2D',\n",
    "    ),\n",
    ")\n",
    "\n",
    "sum(i.numel() for i in model.parameters()) / 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2969101e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(DDPMScheduler {\n",
       "   \"_class_name\": \"DDPMScheduler\",\n",
       "   \"_diffusers_version\": \"0.15.1\",\n",
       "   \"beta_end\": 0.02,\n",
       "   \"beta_schedule\": \"linear\",\n",
       "   \"beta_start\": 0.0001,\n",
       "   \"clip_sample\": true,\n",
       "   \"clip_sample_range\": 1.0,\n",
       "   \"dynamic_thresholding_ratio\": 0.995,\n",
       "   \"num_train_timesteps\": 1000,\n",
       "   \"prediction_type\": \"epsilon\",\n",
       "   \"sample_max_value\": 1.0,\n",
       "   \"thresholding\": false,\n",
       "   \"trained_betas\": null,\n",
       "   \"variance_type\": \"fixed_small\"\n",
       " },\n",
       " AdamW (\n",
       " Parameter Group 0\n",
       "     amsgrad: False\n",
       "     betas: (0.95, 0.999)\n",
       "     capturable: False\n",
       "     eps: 1e-08\n",
       "     foreach: None\n",
       "     initial_lr: 0.0001\n",
       "     lr: 0.0\n",
       "     maximize: False\n",
       "     weight_decay: 1e-06\n",
       " ),\n",
       " <torch.optim.lr_scheduler.LambdaLR at 0x7fdb1003b280>,\n",
       " MSELoss())"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#第3章/初始化工具类\n",
    "from diffusers import DDPMScheduler\n",
    "from diffusers.optimization import get_scheduler\n",
    "\n",
    "scheduler = DDPMScheduler(num_train_timesteps=1000,\n",
    "                          beta_schedule='linear',\n",
    "                          prediction_type='epsilon')\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(),\n",
    "                              lr=1e-4,\n",
    "                              betas=(0.95, 0.999),\n",
    "                              weight_decay=1e-6,\n",
    "                              eps=1e-8)\n",
    "\n",
    "scheduler_lr = get_scheduler('cosine',\n",
    "                             optimizer=optimizer,\n",
    "                             num_warmup_steps=500,\n",
    "                             num_training_steps=len(loader) * 100)\n",
    "\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "scheduler, optimizer, scheduler_lr, criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22436df3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.2061, grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#第3章/定义计算loss的函数\n",
    "def get_loss(image):\n",
    "    device = image.device\n",
    "\n",
    "    #随机噪声\n",
    "    #[b, 3, 64, 64]\n",
    "    noise = torch.randn(image.shape).to(device)\n",
    "\n",
    "    #随机b个噪声步数\n",
    "    #1000 = scheduler.config.num_train_timesteps\n",
    "    #[b]\n",
    "    noise_step = torch.randint(0, 1000, (image.shape[0], ),\n",
    "                               device=device).long()\n",
    "\n",
    "    #往图片当中添加噪声\n",
    "    #[b, 3, 64, 64]\n",
    "    image_noise = scheduler.add_noise(image, noise, noise_step)\n",
    "\n",
    "    #把图片里的噪声计算出来\n",
    "    #[b, 3, 64, 64]\n",
    "    out = model(image_noise, noise_step).sample\n",
    "\n",
    "    #求mse loss\n",
    "    return criterion(out, noise)\n",
    "\n",
    "\n",
    "get_loss(torch.randn(16, 3, 64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31bd73a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 95.75697771087289\n",
      "1 21.93589099915698\n",
      "2 19.333377947565168\n",
      "3 18.43381611024961\n",
      "4 16.366059875115752\n",
      "5 16.564373218920082\n",
      "6 16.268689731601626\n",
      "7 16.676569791976362\n",
      "8 16.546459552831948\n",
      "9 16.88732399744913\n"
     ]
    }
   ],
   "source": [
    "#第3章/训练\n",
    "from diffusers import DDPMPipeline\n",
    "\n",
    "\n",
    "def train():\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "\n",
    "    loss_sum = 0\n",
    "    for epoch in range(10):\n",
    "        for i, data in enumerate(loader):\n",
    "            loss = get_loss(data['image'].to(device))\n",
    "\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            scheduler_lr.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            loss_sum += loss.item()\n",
    "\n",
    "        if epoch % 1 == 0:\n",
    "            print(epoch, loss_sum)\n",
    "            loss_sum = 0\n",
    "\n",
    "    #save\n",
    "    DDPMPipeline(unet=model, scheduler=scheduler).save_pretrained('./save')\n",
    "\n",
    "\n",
    "train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pt39]",
   "language": "python",
   "name": "conda-env-pt39-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
