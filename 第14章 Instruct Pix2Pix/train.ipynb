{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "395e5929",
   "metadata": {},
   "outputs": [],
   "source": [
    "#第14章/全局常量\n",
    "repo_id = 'lansinuote/diffusion.8.instruct_pix2pix'\n",
    "checkpoint = 'runwayml/stable-diffusion-v1-5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d841e29",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration lansinuote--diffusion.8.instruct_pix2pix-5db27ce94b1e4a9e\n",
      "Found cached dataset parquet (/root/.cache/huggingface/datasets/lansinuote___parquet/lansinuote--diffusion.8.instruct_pix2pix-5db27ce94b1e4a9e/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input torch.Size([3, 256, 256]) torch.float32\n",
      "output torch.Size([3, 256, 256]) torch.float32\n",
      "text torch.Size([77]) torch.int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input', 'text', 'output'],\n",
       "    num_rows: 1000\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#第14章/加载数据集\n",
    "from datasets import load_dataset\n",
    "from transformers import CLIPTokenizer\n",
    "import torchvision\n",
    "\n",
    "tokenizer = CLIPTokenizer.from_pretrained(checkpoint, subfolder='tokenizer')\n",
    "\n",
    "compose = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize(256),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    lambda x: (x * 2) - 1,\n",
    "])\n",
    "\n",
    "#转载自fusing/instructpix2pix-1000-samples\n",
    "dataset = load_dataset(path=repo_id, split='train')\n",
    "\n",
    "\n",
    "def f(data):\n",
    "    #图像编码\n",
    "    input = [compose(i) for i in data['input']]\n",
    "    output = [compose(i) for i in data['output']]\n",
    "\n",
    "    #文字编码\n",
    "    #77 = tokenizer.model_max_length\n",
    "    text = tokenizer.batch_encode_plus(data['text'],\n",
    "                                       max_length=77,\n",
    "                                       padding='max_length',\n",
    "                                       truncation=True,\n",
    "                                       return_tensors='pt').input_ids\n",
    "\n",
    "    return {'input': input, 'output': output, 'text': text}\n",
    "\n",
    "\n",
    "dataset = dataset.with_transform(f)\n",
    "\n",
    "for k, v in dataset[0].items():\n",
    "    print(k, v.shape, v.dtype)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43037e7c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input torch.Size([4, 3, 256, 256]) torch.float32\n",
      "output torch.Size([4, 3, 256, 256]) torch.float32\n",
      "text torch.Size([4, 77]) torch.int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "250"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#第14章/定义loader\n",
    "import torch\n",
    "\n",
    "loader = torch.utils.data.DataLoader(dataset,\n",
    "                                     shuffle=True,\n",
    "                                     collate_fn=None,\n",
    "                                     batch_size=4)\n",
    "\n",
    "for k, v in next(iter(loader)).items():\n",
    "    print(k, v.shape, v.dtype)\n",
    "\n",
    "len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "217c0a9c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "encoder 12306.048\n",
      "vae 8365.3863\n",
      "unet 85953.2484\n"
     ]
    }
   ],
   "source": [
    "#第14章/加载模型\n",
    "from diffusers import AutoencoderKL, UNet2DConditionModel, ControlNetModel\n",
    "from transformers import CLIPTextModel\n",
    "\n",
    "#加载3个模型\n",
    "encoder = CLIPTextModel.from_pretrained(checkpoint, subfolder='text_encoder')\n",
    "vae = AutoencoderKL.from_pretrained(checkpoint, subfolder='vae')\n",
    "unet = UNet2DConditionModel.from_pretrained(checkpoint, subfolder='unet')\n",
    "\n",
    "#修改unet.conv_in层的形状\n",
    "unet.register_to_config(in_channels=8)\n",
    "with torch.no_grad():\n",
    "    new_conv_in = torch.nn.Conv2d(8, 320, 3, 1, 1)\n",
    "    new_conv_in.weight.zero_()\n",
    "    new_conv_in.weight[:, :4, :, :].copy_(unet.conv_in.weight)\n",
    "    unet.conv_in = new_conv_in\n",
    "print(unet.config.in_channels)\n",
    "\n",
    "\n",
    "def print_model_size(name, model):\n",
    "    print(name, sum(i.numel() for i in model.parameters()) / 10000)\n",
    "\n",
    "\n",
    "print_model_size('encoder', encoder)\n",
    "print_model_size('vae', vae)\n",
    "print_model_size('unet', unet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5f838ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(DDPMScheduler {\n",
       "   \"_class_name\": \"DDPMScheduler\",\n",
       "   \"_diffusers_version\": \"0.15.1\",\n",
       "   \"beta_end\": 0.012,\n",
       "   \"beta_schedule\": \"scaled_linear\",\n",
       "   \"beta_start\": 0.00085,\n",
       "   \"clip_sample\": false,\n",
       "   \"clip_sample_range\": 1.0,\n",
       "   \"dynamic_thresholding_ratio\": 0.995,\n",
       "   \"num_train_timesteps\": 1000,\n",
       "   \"prediction_type\": \"epsilon\",\n",
       "   \"sample_max_value\": 1.0,\n",
       "   \"set_alpha_to_one\": false,\n",
       "   \"skip_prk_steps\": true,\n",
       "   \"steps_offset\": 1,\n",
       "   \"thresholding\": false,\n",
       "   \"trained_betas\": null,\n",
       "   \"variance_type\": \"fixed_small\"\n",
       " },\n",
       " AdamW (\n",
       " Parameter Group 0\n",
       "     amsgrad: False\n",
       "     betas: (0.9, 0.999)\n",
       "     capturable: False\n",
       "     eps: 1e-08\n",
       "     foreach: None\n",
       "     lr: 5e-05\n",
       "     maximize: False\n",
       "     weight_decay: 0.01\n",
       " ),\n",
       " MSELoss())"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#第14章/初始化工具类\n",
    "from diffusers import DDPMScheduler\n",
    "\n",
    "scheduler = DDPMScheduler.from_pretrained(checkpoint, subfolder='scheduler')\n",
    "\n",
    "optimizer = torch.optim.AdamW(unet.parameters(),\n",
    "                              lr=5e-5,\n",
    "                              betas=(0.9, 0.999),\n",
    "                              weight_decay=0.01,\n",
    "                              eps=1e-8)\n",
    "\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "scheduler, optimizer, criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b766d5c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 77, 768]), torch.Size([4, 4, 32, 32]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#第14章/定义dropout部分数据的辅助函数\n",
    "def dropout_data(out_encoder, input):\n",
    "    #输入图编码\n",
    "    #[4, 3, 256, 256] -> [4, 4, 32, 32]\n",
    "    out_vae_input = vae.encode(input).latent_dist.mode()\n",
    "\n",
    "    #生成mask\n",
    "    r = torch.rand(4, device=out_encoder.device)\n",
    "    #[4, 1, 1]\n",
    "    mask_text = (r > 0.1).reshape(4, 1, 1)\n",
    "    #[4, 1, 1, 1]\n",
    "    mask_image = torch.logical_or(r < 0.05,\n",
    "                                  r > 0.15).float().reshape(4, 1, 1, 1)\n",
    "\n",
    "    #编码负采样的文本\n",
    "    out_encoder_neg = tokenizer.batch_encode_plus(\n",
    "        [''],\n",
    "        max_length=77,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_tensors='pt').input_ids.to(out_encoder.device)\n",
    "    out_encoder_neg = encoder(out_encoder_neg)[0]\n",
    "\n",
    "    #使用mask混合正负编码\n",
    "    #文本大概率选择正编码\n",
    "    #[4, 77, 768]\n",
    "    out_encoder = torch.where(mask_text, out_encoder, out_encoder_neg)\n",
    "\n",
    "    #图像小概率归零\n",
    "    #[4, 4, 32, 32]\n",
    "    out_vae_input = mask_image * out_vae_input\n",
    "\n",
    "    return out_encoder, out_vae_input\n",
    "\n",
    "\n",
    "out = dropout_data(out_encoder=torch.randn(4, 77, 768),\n",
    "                   input=torch.randn(4, 3, 256, 256))\n",
    "\n",
    "out[0].shape, out[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3f32e9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0932, grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#第14章/定义计算loss的函数\n",
    "def get_loss(data):\n",
    "    #文字编码\n",
    "    #[4, 77] -> [4, 77, 768]\n",
    "    out_encoder = encoder(data['text'])[0]\n",
    "\n",
    "    #输出图编码\n",
    "    #[4, 3, 256, 256] -> [4, 4, 32, 32]\n",
    "    out_vae_output = vae.encode(data['output']).latent_dist.sample()\n",
    "    #0.18215 = vae.config.scaling_factor\n",
    "    out_vae_output = out_vae_output * 0.18215\n",
    "\n",
    "    #随机噪声\n",
    "    #[4, 4, 32, 32]\n",
    "    noise = torch.randn_like(out_vae_output)\n",
    "\n",
    "    #往特征图中添加噪声\n",
    "    #1000 = scheduler.num_train_timesteps\n",
    "    #4 = out_vae.shape[0]\n",
    "    noise_step = torch.randint(0, 1000, (4, )).long()\n",
    "    noise_step = noise_step.to(out_encoder.device)\n",
    "    #[4, 4, 32, 32]\n",
    "    out_vae_noise = scheduler.add_noise(out_vae_output, noise, noise_step)\n",
    "\n",
    "    #使用mask组合正负采样的文本编码数据\n",
    "    #输入图编码\n",
    "    #[4, 77, 768],[4, 4, 32, 32]\n",
    "    out_encoder, out_vae_input = dropout_data(out_encoder=out_encoder,\n",
    "                                              input=data['input'])\n",
    "\n",
    "    #向out_vae_noise中组合输入图的数据\n",
    "    #[4, 4+4, 32, 32] -> [4, 8, 32, 32]\n",
    "    out_vae_noise = torch.cat([out_vae_noise, out_vae_input], dim=1)\n",
    "\n",
    "    #根据文字信息,把特征图中的噪声计算出来\n",
    "    #[4, 4, 32, 32]\n",
    "    out_unet = unet(out_vae_noise,\n",
    "                    noise_step,\n",
    "                    encoder_hidden_states=out_encoder).sample\n",
    "\n",
    "    #计算loss\n",
    "    #[4, 4, 32, 32],[4, 4, 32, 32]\n",
    "    return criterion(out_unet, noise)\n",
    "\n",
    "\n",
    "get_loss({\n",
    "    'text': torch.ones(4, 77).long(),\n",
    "    'input': torch.randn(4, 3, 256, 256),\n",
    "    'output': torch.randn(4, 3, 256, 256),\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84b88599",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#第14章/训练\n",
    "from diffusers import StableDiffusionPipeline\n",
    "\n",
    "\n",
    "def train():\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "    unet.to(device)\n",
    "    encoder.to(device)\n",
    "    vae.to(device)\n",
    "\n",
    "    vae.requires_grad_(False)\n",
    "    encoder.requires_grad_(False)\n",
    "    unet.train()\n",
    "\n",
    "    loss_sum = 0\n",
    "    for epoch in range(4000):\n",
    "        for i, data in enumerate(loader):\n",
    "            for k in data.keys():\n",
    "                data[k] = data[k].to(device)\n",
    "\n",
    "            loss = get_loss(data) / 4\n",
    "            loss.backward()\n",
    "            loss_sum += loss.item()\n",
    "\n",
    "            if i % 4 == 0:\n",
    "                torch.nn.utils.clip_grad_norm_(unet.parameters(), 1.0)\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "        if (epoch + 1) % 20 == 0:\n",
    "            print(epoch, loss_sum)\n",
    "            loss_sum = 0\n",
    "\n",
    "            #保存\n",
    "            StableDiffusionPipeline.from_pretrained(\n",
    "                checkpoint, text_encoder=encoder, vae=vae,\n",
    "                unet=unet).save_pretrained('./save')\n",
    "\n",
    "\n",
    "#train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pt39]",
   "language": "python",
   "name": "conda-env-pt39-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
